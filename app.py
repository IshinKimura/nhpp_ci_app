import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
from scipy.optimize import minimize
from scipy.stats import norm, chi2, poisson

# --- æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆï¼ˆå¿…è¦ãªã‚‰ï¼‰ ---
plt.rcParams['font.family'] = 'MS Gothic'

# --- ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ ---
fault_data = np.array([6, 1, 1, 0, 1, 3, 0, 5, 6, 1, 0, 3, 9, 3, 2, 3, 0, 2, 4, 0, 0, 0, 0, 0, 2, 0, 0, 2, 3, 11, 5, 3, 2, 4, 2, 0, 1, 2, 0, 1, 3, 0, 1, 6, 2, 0, 5, 10, 3, 3, 2, 1, 0, 3, 0, 2, 0, 1, 0, 1, 0, 2])
t = np.arange(1, len(fault_data) + 1)
y = np.cumsum(fault_data)

# --- é–¢æ•°å®šç¾© ---
def mean_value_function(t, a, b):
    return a * (1 - np.exp(-b * t))

def log_likelihood(params, t, y):
    a, b = params
    n = len(t)
    logL = 0
    for k in range(1, n):
        delta_y = y[k] - y[k - 1]
        delta_lambda = a * (np.exp(-b * t[k - 1]) - np.exp(-b * t[k]))
        if delta_y > 0 and delta_lambda > 0:
            logL += delta_y * np.log(delta_lambda) - delta_lambda - np.sum(np.log(np.arange(1, delta_y + 1)))
        else:
            logL -= delta_lambda
    return -logL

def fisher_information(a, b, t, y):
    n = len(t)
    I = np.zeros((2, 2))
    for k in range(1, n):
        delta_y = y[k] - y[k - 1]
        exp1 = np.exp(-b * t[k - 1])
        exp2 = np.exp(-b * t[k])
        dL_da = exp1 - exp2
        dL_db = a * (-t[k - 1] * exp1 + t[k] * exp2)
        delta_lambda = a * (exp1 - exp2)
        if delta_lambda > 0:
            I[0, 0] += (dL_da ** 2) / delta_lambda
            I[0, 1] += (dL_da * dL_db) / delta_lambda
            I[1, 1] += (dL_db ** 2) / delta_lambda
    I[1, 0] = I[0, 1]
    return I

def wilks_stat(a, t, y, mle_b, mle_ll):
    def neg_log_likelihood_b(b):
        return -log_likelihood([a, b], t, y)
    res_b = minimize(neg_log_likelihood_b, mle_b, bounds=[(0.001, 0.1)])
    ll_a = -res_b.fun
    return 2 * (mle_ll - ll_a)

# --- Streamlit ã‚¢ãƒ—ãƒª ---
st.markdown("## ğŸ“Š æŒ‡æ•°å‹NHPPãƒ¢ãƒ‡ãƒ«ï¼šä¿¡é ¼åŒºé–“ã®å¯è¦–åŒ–ãƒ„ãƒ¼ãƒ«")


methods = st.multiselect(
    "ä¿¡é ¼åŒºé–“ã®æ§‹ç¯‰æ‰‹æ³•ã‚’é¸ã‚“ã§ãã ã•ã„",
    ["Wilksã®å°¤åº¦æ¯”æ¤œå®š", "ãƒ•ã‚£ãƒƒã‚·ãƒ£ãƒ¼æƒ…å ±è¡Œåˆ—ï¼ˆè¿‘ä¼¼æ­£è¦ï¼‰", "ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³", "ä¸€èˆ¬çš„ãªæ­£è¦è¿‘ä¼¼"],
    default=["ãƒ•ã‚£ãƒƒã‚·ãƒ£ãƒ¼æƒ…å ±è¡Œåˆ—ï¼ˆè¿‘ä¼¼æ­£è¦ï¼‰"]
)

if st.button("ä¿¡é ¼åŒºé–“ã‚’è¨ˆç®—ã—ã¦è¡¨ç¤º"):
    # --- MLEæ¨å®š ---
    init = [300, 0.009]
    bounds = [(1, 1000), (0.001, 0.1)]
    res = minimize(log_likelihood, init, args=(t, y), method='L-BFGS-B', bounds=bounds)
    a_hat, b_hat = res.x
    mle_ll = -res.fun
    Lambda_hat = mean_value_function(t, a_hat, b_hat)

    # --- ã‚°ãƒ©ãƒ•ä½œæˆ ---
    fig, ax = plt.subplots(figsize=(10, 6))
    ax.plot(t, y, label="å®Ÿãƒ‡ãƒ¼ã‚¿", color='black')
    ax.plot(t, Lambda_hat, label="å¹³å‡å€¤é–¢æ•°", color='blue')

    # --- Wilks ---
    if "Wilksã®å°¤åº¦æ¯”æ¤œå®š" in methods:
        a_vals = np.linspace(0.5 * a_hat, 1.5 * a_hat, 100)
        chi2_crit = chi2.ppf(0.95, df=1)
        wilks_vals = np.array([wilks_stat(a, t, y, b_hat, mle_ll) for a in a_vals])
        ci_a = a_vals[wilks_vals <= chi2_crit]
        if len(ci_a) > 0:
            a_lower, a_upper = np.min(ci_a), np.max(ci_a)
            ax.plot(t, mean_value_function(t, a_lower, b_hat), color='green', linestyle='--', label="Wilksä¸‹é™")
            ax.plot(t, mean_value_function(t, a_upper, b_hat), color='green', linestyle='--', label="Wilksä¸Šé™")

    # --- Fisher ---
    if "ãƒ•ã‚£ãƒƒã‚·ãƒ£ãƒ¼æƒ…å ±è¡Œåˆ—ï¼ˆè¿‘ä¼¼æ­£è¦ï¼‰" in methods:
        I = fisher_information(a_hat, b_hat, t, y)
        cov = np.linalg.inv(I)
        se_a = np.sqrt(cov[0, 0])
        z = norm.ppf(0.975)
        a_lower = a_hat - z * se_a
        a_upper = a_hat + z * se_a
        ax.plot(t, mean_value_function(t, a_lower, b_hat), color='red', linestyle='-.', label="è¿‘ä¼¼æ­£è¦ä¸‹é™")
        ax.plot(t, mean_value_function(t, a_upper, b_hat), color='red', linestyle='-.', label="è¿‘ä¼¼æ­£è¦ä¸Šé™")

    # --- Simulation ---
    if "ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³" in methods:
        sim_lower = []
        sim_upper = []
        for t_val in t:
            mu = mean_value_function(t_val, a_hat, b_hat)
            samples = poisson.rvs(mu, size=10000)
            sim_lower.append(np.percentile(samples, 2.5))
            sim_upper.append(np.percentile(samples, 97.5))
        ax.plot(t, sim_lower, color='purple', linestyle=':', label="ã‚·ãƒŸãƒ¥ä¸‹é™")
        ax.plot(t, sim_upper, color='purple', linestyle=':', label="ã‚·ãƒŸãƒ¥ä¸Šé™")

    # --- General Normal Approximation ---
    if "ä¸€èˆ¬çš„ãªæ­£è¦è¿‘ä¼¼" in methods:
        z = norm.ppf(0.975)
        ci_lower = Lambda_hat - z * np.sqrt(Lambda_hat)
        ci_upper = Lambda_hat + z * np.sqrt(Lambda_hat)
        ax.plot(t, ci_lower, color='orange', linestyle=':', label="æ­£è¦è¿‘ä¼¼ä¸‹é™")
        ax.plot(t, ci_upper, color='orange', linestyle=':', label="æ­£è¦è¿‘ä¼¼ä¸Šé™")

    ax.set_xlabel("æ™‚åˆ» t")
    ax.set_ylabel("ç´¯ç©æ•…éšœæ•°")
    ax.set_title("ä¿¡é ¼åŒºé–“ã®æ¯”è¼ƒï¼ˆé¸æŠæ‰‹æ³•ï¼‰")
    ax.legend()
    ax.grid(True)
    st.pyplot(fig)
